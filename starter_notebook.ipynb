{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Building Time Series Forecasts\n",
    "\n",
    "**Student Name:** [Your Name Here]\n",
    "\n",
    "**Date:** [Date]\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "In this assignment, you'll analyze temporal data from Corporación Favorita stores to identify trends, seasonality, and anomalies, then build forecasting models using decomposition techniques. You'll work with real retail sales data to predict future sales patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Data, Import Libraries, and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets for this analysis are too large too be stored on GitHub. To access the datasets for this assignment, you should:\n",
    "- Go to the [Store Sales - Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data) dataset on Kaggle.\n",
    "- Click Data \n",
    "- Scroll down and select **Download All**.\n",
    "- Open the zip file and upload `train.csv`, `store.csv`, and `holidays_events.csv` to the `data` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the CSV files have been added to the `data` directory, install all the of the necessary libraries for this assignment by running the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib seaborn scikit-learn statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# For time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load the training, store, and holiday CSV data from the `data` directory using `pd.read_csv()`. Display basic information about the training data and print out the first few rows to get an understanding of what the training data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# TODO: Load all three required CSV files\n",
    "train_df = None  # Replace with pd.read_csv('data/train.csv')\n",
    "holidays_df = None  # Replace with pd.read_csv('data/holidays_events.csv')\n",
    "stores_df = None  # Replace with pd.read_csv('data/stores.csv')\n",
    "\n",
    "# Display basic information\n",
    "if train_df is not None:\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Date range: {train_df['date'].min()} to {train_df['date'].max()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    # TODO: Display the first few rows\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKPOINT: Verify datasets loaded correctly\")\n",
    "print(f\"Train data shape: {train_df.shape if train_df is not None else 'Not loaded'}\")\n",
    "print(f\"Holidays data shape: {holidays_df.shape if holidays_df is not None else 'Not loaded'}\")\n",
    "print(f\"Stores data shape: {stores_df.shape if stores_df is not None else 'Not loaded'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Available Stores and Product Families\n",
    "Display store information from `stores_df` to help choose a store. Consider looking at store type, cluster, and city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data to help choose your store and products\n",
    "if train_df is not None:\n",
    "    print(\"Available stores:\")\n",
    "    print(f\"Total number of stores: {train_df['store_nbr'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nAvailable product families:\")\n",
    "    families = train_df['family'].value_counts().head(20)\n",
    "    print(families)\n",
    "    \n",
    "    # TODO: Display store information from stores_df to help choose a store\n",
    "    # Consider looking at store type, cluster, and city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Select and Prepare Your Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Your Store and Product Families\n",
    "\n",
    "Choose one store and one product family (PRODUCE, BEVERAGES, BREAD/BAKERY, AUTOMOTIVE, etc.) to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select your store and product family\n",
    "selected_store = None  # Replace with your chosen store number (e.g., 1)\n",
    "product_family_1 = None  # Replace with the product family you selected (e.g., 'PRODUCE')\n",
    "\n",
    "print(f\"Selected Store: {selected_store}\")\n",
    "print(f\"Product Family 1: {product_family_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data\n",
    "Filter the `train_df` data to your selected store and products. Create a date range from 2016-01-01 to 2017-08-15 for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Filter train_df for selected store and date range 2016-01-01 to 2017-08-15\n",
    "\n",
    "# Convert date column to datetime if needed\n",
    "if train_df is not None:\n",
    "    train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "\n",
    "# Filter for date range\n",
    "start_date = '2016-01-01'\n",
    "end_date = '2017-08-15'\n",
    "\n",
    "# TODO: Create filtered datasets for each product family\n",
    "product1_data = None  # Filter for store, product_family_1, and date range\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKPOINT: Data filtered successfully\")\n",
    "print(f\"Product data shape: {product1_data.shape if product1_data is not None else 'Not filtered'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Daily Sales\n",
    "Aggregate daily sales and handle missing dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Group by date and sum sales for each product family\n",
    "# TODO: Create a complete date range and fill missing dates with 0 sales\n",
    "\n",
    "# Example structure (replace with your implementation):\n",
    "# date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# product1_ts = product1_data.groupby('date')['sales'].sum().reindex(date_range, fill_value=0)\n",
    "\n",
    "product1_ts = None  # Replace with time series for your selected product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Raw Time Series\n",
    "Plot time series to see the raw patterns using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Product 1\n",
    "# TODO: Plot product1_ts on a line chart as a time series\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Your Choice (2-3 sentences)\n",
    "Explain why you chose this product. \n",
    "- What contrasts do they represent? \n",
    "- Why will they be interesting to compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ REPLACE WITH YOUR JUSTIFICATION ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Identify Trends Using Moving Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Moving Averages\n",
    "Calculate the 7-day and 30-day moving averages for the product you are analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate 7-day and 30-day moving averages for your product\n",
    "\n",
    "# For Product 1\n",
    "product1_ma7 = None  # Replace with product1_ts.rolling(window=7).mean()\n",
    "product1_ma30 = None  # Replace with product1_ts.rolling(window=30).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Original Sales\n",
    "Using matplotlip, plot original sales with both moving averages (7-day and 30-day) overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot original sales with moving averages\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Product 1\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# TODO: Plot original, 7-day MA, and 30-day MA for product 1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# axes[0].plot(product1_ts.index, product1_ts.values, alpha=0.4, label='Daily Sales')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# axes[0].plot(product1_ma7.index, product1_ma7.values, label='7-Day MA')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# axes[0].plot(product1_ma30.index, product1_ma30.values, label='30-Day MA')\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot original sales with moving averages\n",
    "fig, axes = plt.subplots(1, 1, figsize=(14, 6))\n",
    "\n",
    "# Product 1\n",
    "# TODO: Plot original, 7-day MA, and 30-day MA for product 1\n",
    "# axes[0].plot(product1_ts.index, product1_ts.values, alpha=0.4, label='Daily Sales')\n",
    "# axes[0].plot(product1_ma7.index, product1_ma7.values, label='7-Day MA')\n",
    "# axes[0].plot(product1_ma30.index, product1_ma30.values, label='30-Day MA')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Explain Trend Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the data with `holidays_events.csv` to explain what caused these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with holidays to explain trend changes\n",
    "# TODO: Convert holidays_df date to datetime and filter for your date range\n",
    "if holidays_df is not None:\n",
    "    holidays_df['date'] = pd.to_datetime(holidays_df['date'])\n",
    "    relevant_holidays = None  # Filter holidays_df for your date range\n",
    "    \n",
    "    # TODO: Display holidays that might explain trend changes\n",
    "    print(\"Key holidays/events in the period:\")\n",
    "    # Display relevant holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Trend Analysis\n",
    "For the product family you are analyzing, document:\n",
    "1. Overall trend direction (growing, declining, stable)\n",
    "2. Any trend changes that correlate with holidays or events\n",
    "3. Business implications of the trends you discovered\n",
    "\n",
    "Update the markdown cell below with your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Product Trends:**\n",
    "- Overall trend direction: [ Growing/Declining/Stable? ]\n",
    "- Key trend changes: [ List at least 3 significant changes and dates ]\n",
    "- Holiday correlations: [ Which holidays affected sales? ]\n",
    "- Business implications: [ What do these trends mean for inventory ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Detect and Visualize Seasonal Patterns\n",
    "\n",
    "Analyze the seasonal components of your sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day-of-Week Analysis\n",
    "\n",
    "Add day of week to your data and calculate the average sales by day. Create a bar plot to visualize the weekday patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze day-of-week patterns\n",
    "# TODO: Add day of week to your data and calculate average sales by day\n",
    "product1_dow = None  # Create DataFrame with date and sales\n",
    "\n",
    "# Add day of week: product1_dow['day_of_week'] = product1_dow.index.day_name()\n",
    "# Group by day of week and calculate mean sales\n",
    "\n",
    "\n",
    "# Create bar plot comparing weekday patterns\n",
    "# TODO: Create bar plot showing average sales by day of week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Seasonality Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average sales by month for both products. Once calculated, create a line plot showing monthly patterns for the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze monthly patterns\n",
    "# TODO: Calculate average sales by month for the product.\n",
    "\n",
    "# For Product 1\n",
    "product1_monthly = None  # Group by month and calculate mean sales\n",
    "\n",
    "\n",
    "# Create visualization\n",
    "# TODO: Create line plot showing monthly patterns for both products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Impact Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the average sales on holidays compared to regular days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze holiday vs non-holiday sales\n",
    "# TODO: Compare average sales on holidays vs regular days\n",
    "\n",
    "# Create a list of holiday dates\n",
    "holiday_dates = None  # Extract unique dates from holidays_df\n",
    "\n",
    "# Calculate average sales on holidays vs non-holidays for both products\n",
    "# TODO: Split data into holiday and non-holiday sales and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Pattern Findings\n",
    "\n",
    "**Document your findings:**\n",
    "- Which days of the week have highest/lowest sales?\n",
    "- Are there monthly patterns (e.g., payday effects)?\n",
    "- How do holidays affect each product differently?\n",
    "- What business decisions could these patterns inform?\n",
    "\n",
    "Update the markdown cell below with your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ Write your analysis here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Build Simple Forecasts and Compare Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition\n",
    "# TODO: Use seasonal_decompose to separate trend, seasonal, and residual components\n",
    "\n",
    "# For Product 1\n",
    "decomposition1 = None  # seasonal_decompose(product1_ts, model='additive', period=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decomposition for Product 1\n",
    "if decomposition1 is not None:\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "    \n",
    "    # TODO: Plot each component\n",
    "    # decomposition1.observed.plot(ax=axes[0], title=f'{product_family_1} - Original')\n",
    "    # decomposition1.trend.plot(ax=axes[1], title='Trend')\n",
    "    # decomposition1.seasonal.plot(ax=axes[2], title='Seasonal')\n",
    "    # decomposition1.resid.plot(ax=axes[3], title='Residual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Forecasts\n",
    "Create a baseline forecast using the average of the last 30 days and a season naive forcast by repeating the last 7 days' pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for validation\n",
    "test_days = 30\n",
    "train = None # product1_ts[:-test_days]\n",
    "test = None # product1_ts[-test_days:]\n",
    "\n",
    "# Method 1: Baseline forecast (30-day average)\n",
    "baseline_forecast = np.repeat(train[-30:].mean(), test_days)\n",
    "\n",
    "# Method 2: Seasonal Naive\n",
    "# Just repeat the last 7 days pattern\n",
    "last_week = train[-7:].values\n",
    "seasonal_naive_forecast = np.tile(last_week, int(np.ceil(test_days/7)))[:test_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Forecast Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE for both methods\n",
    "# TODO: Calculate RMSE for baseline and seasonal forecasts\n",
    "\n",
    "# Product 1\n",
    "baseline_rmse = None  # np.sqrt(mean_squared_error(test1, baseline_forecast1)\n",
    "seasonal_rmse = None  # np.sqrt(mean_squared_error(test1, seasonal_naive_forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Method': ['30-Day Average', 'Seasonal Naive (7-day repeat)'],\n",
    "    'RMSE': [baseline_rmse, seasonal_rmse],\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# TODO: Calculate percentage improvement\n",
    "# Add improvement column to comparison_df\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FORECAST PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "# TODO: Display comparison table\n",
    "\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs forecasted values\n",
    "# TODO: Create visualization showing:\n",
    "# - Historical data (last 60 days of train)\n",
    "# - Actual test data\n",
    "# - Baseline forecast\n",
    "# - Seasonal naive forecast\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "\n",
    "# TODO: Plot on this single figure\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Generate Business Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executive Summary (200-300 words)\n",
    "\n",
    "Based on your analysis, write a brief executive summary that includes:\n",
    "- **Key Patterns Discovered:** Summarize the main trends and seasonal patterns for each product\n",
    "- **Inventory Planning Recommendations:** Specific recommendations based on your findings\n",
    "- **High-Risk Periods:** Identify periods requiring special attention\n",
    "- **Predictability Analysis:** Which product is more predictable and why?\n",
    "- **Specific Action Item:** One concrete action the store manager should take based on your forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ Write your 200 to 300 word executive summary here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Submit Your Work\n",
    "\n",
    "Before submitting:\n",
    "1. Ensure all code cells run without errors\n",
    "2. Verify all visualizations display correctly\n",
    "3. Check that your analysis sections are complete\n",
    "4. Review your executive summary\n",
    "\n",
    "Push to GitHub:\n",
    "```bash\n",
    "git add .\n",
    "git commit -m 'completed time series forecasting assignment'\n",
    "git push\n",
    "```\n",
    "\n",
    "Submit your GitHub repository link on the course platform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
